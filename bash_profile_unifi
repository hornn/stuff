
PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/local/bin:/opt/local/sbin
PATH=$PATH:/usr/local/git/bin:/usr/local/opt/sbt/bin:
export PATH=/usr/local/mysql/bin:$PATH

# Useful aliases:
alias ll="ls -l"
alias jps="jps | sort -k 2"
#alias bt="/Users/nhorn/scripts/beep_test.sh"
function bt()
{
echo -e "Done!" "\a" "\a" "\a"
#echo "Done testing" "\007" "\007" "\007" # beep beep beep
}
alias p4diff="/Applications/p4merge.app/Contents/MacOS/p4merge"

# kill postgres remains:
alias killpostgres='killall postgres; ipcclean; rm -f /tmp/.s*'

function maxof()
{
re='^[0-9]+$'
if ! [[ $1 =~ $re ]]; then
echo "Usage: maxof <open files threshold>"
return 1
fi
pids=`ps -ef | awk '{print $2}' | grep -v PID`; 
for i in $pids; do 
	b=$(lsof -p $i | wc -l) ; 
	if [[ $b -gt $1 ]]; then 
		p=$(ps -p $i);
		echo $b, $i, $p; 
	fi; 
done | sort -n
}


# vm 
alias ssh_vm="ssh hornn@vm-centos64"

# beep test:
function beep_test()
{

$*
echo -e "Done!" "\a" "\a" "\a"
#echo "Done testing" "\007" "\007" "\007" # beep beep beep

}


function gitundo()
{
git log -1
git reset --soft HEAD~1
}

export GITAWAREPROMPT=~/.bash/git-aware-prompt
source "${GITAWAREPROMPT}/main.sh"
export PS1="\u@\h \W \[$txtcyn\]\$git_branch\[$txtred\]\$git_dirty\[$txtrst\]\$ "
source ~/.bash/git-completion.bash

### Unifi ###
# active virtual env:
alias activate='source ~/dev/unifi_virtenv/bin/activate'
# start/stop postgres
alias start_postgres='pg_ctl -D /usr/local/var/postgres/ -l /usr/local/var/postgres/server.log start'
alias stop_postgres='pg_ctl -D /usr/local/var/postgres/ stop'
# start/stop hdfs
alias start_hdfs='/usr/local/Cellar/hadoop/2.7.2/sbin/start-dfs.sh'
alias stop_hdfs='/usr/local/Cellar/hadoop/2.7.2/sbin/stop-dfs.sh'
# start/stop yarn
alias start_yarn='/usr/local/Cellar/hadoop/2.7.2/sbin/start-yarn.sh'
alias stop_yarn='/usr/local/Cellar/hadoop/2.7.2/sbin/stop-yarn.sh'
# start hive
alias start_hive='hiveserver2 &'
# stop hive
function stop_hive()
{
	echo "killing hiveserver2..."
	ps -ef | grep HiveServer2 | awk '{print $2}' | xargs kill -9 
}

# start all (postgres + hdfs + yarn + hiveserver2)
function start_all()
{
	start_postgres
	start_hdfs
	hdfs dfsadmin -safemode wait
	start_yarn
	start_hive
}
function stop_all()
{
	stop_postgres
	stop_hdfs
	stop_yarn
	stop_hive
}

# install, start, stop unifi
alias unifi_start='/Users/nhorn/dev/unifing/scripts/sbin/unifi_start --executor-mode local'
alias unifi_status='/Users/nhorn/dev/unifing/scripts/sbin/unifi_status'
alias unifi_stop='/Users/nhorn/dev/unifing/scripts/sbin/unifi_stop'
alias unifi_restart='/Users/nhorn/dev/unifing/scripts/sbin/unifi_restart --executor-mode local'
function unifi_restart_old() {
  stop_params=''
  stop_list='--all --celery --solr --discovery --executor --access --integration --redis'
  for var in "$@"; do
    if [[ $stop_list =~ $var ]]; then
      stop_params="${stop_params}${var}"
    fi;
  done;
  echo "stop params: $stop_params";
  unifi_stop $stop_params;
  echo "start params: $@";
  unifi_start $@;
}

alias unifi_build='unifi_stop && gradle clean && gradle build --parallel --max-workers=4 -Pfastpack=true; bt'
alias unifi_build_offline='unifi_stop && gradle clean && gradle build --parallel --max-workers=4 -Pfastpack=true --offline; bt'
alias unifi_clean_cache='rm -r /Users/nhorn/dev/unifing/services/data-integration/unifi_www/datai/static/angular/.cache/'
alias unifi_install_default='rm /Users/nhorn/dev/unifing/services/data-integration/unifi_www/unifi_www/settings.py ; rm /Users/nhorn/dev/unifing/ext/redis/3.0.1/dump.rdb ; /Users/nhorn/dev/unifing/scripts/sbin/unifi_install --dbhost=127.0.0.1 --dbport=5432 --dbuser=unifi --dbpass='\'''\'' --dbname=unifi --unifiuser=unifi --unifipass=unifiU1! --unifiemail=noa@unifisoftware.com --unififirstname Noa --unifilastname Horn --install-missing-deps'
alias unifi_install_demo='cd /Users/nhorn/dev/unifing/demo ; python setup.py --unifiuser=unifi --unifipass=unifiU1! --all; cd -'
#alias unifi_install_demo='cd /Users/nhorn/dev/unifing/demo ; python setup.py --unifiuser=unifi --unifipass=unifiU1! --db --hdfs --s3 --azure-blob --gs --service; cd -'
alias unifi_reinstall='unifi_stop ; dropdb unifi ; unifi_install_default ; unifi_start ; unifi_install_demo'
alias gotoapi='cd /Users/nhorn/dev/unifing/services/data-integration/unifi_www/'
alias gotobase='cd /Users/nhorn/dev/unifing/'
alias gototest='cd /Users/nhorn/dev/unifing/test/'
function unifi_test()
{
if [[ "$1" == "" ]]; then
    echo "Usage: unifi_test <keyword>"
    return 1
fi
keyword=$1
gototest
(set -x; python regression.py --keyword $keyword --pytest-args='-s' --keep-changes --extended)
cd -
}
alias unifi_log='/Users/nhorn/dev/unifing/scripts/sbin/unifi_log'
alias curlaccess="psql unifi -c \"select key from authtoken_token\" -t | xargs -I % echo \"curl -H \\\"Authorization: Token\" %\\\""

export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/
export JDK7_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/

export HADOOP_HOME=/usr/local/Cellar/hadoop/2.7.2/libexec/
export HADOOP_VERSION="2.7.2"
export HADOOP_CONF_DIR=/usr/local/Cellar/hadoop/2.7.2/libexec/etc/hadoop/
export HIVE_HOME=/usr/local/Cellar/hive/2.1.0/libexec/
export HIVE_CONF_DIR=/usr/local/Cellar/hive/2.1.0/libexec/conf/
#export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:/opt/cloudera/hiveodbc/lib/universal:/usr/local/opt/unixodbc/lib/libodbc
export SPARK_HOME=/usr/local/spark
export PATH=${SPARK_HOME}/bin:$PATH

export BOOST_PYTHON="boost_python-mt"
export PATH=/opt/solr/bin:$PATH

# docker params
export DOCKER_HOST=tcp://192.168.59.103:2376
export DOCKER_CERT_PATH=/Users/nhorn/.boot2docker/certs/boot2docker-vm
export DOCKER_TLS_VERIFY=1

# run gcloud instance
function gcloud_run()
{
  if [[ "$1" == "" ]]; then
    echo "Usage: gcloud_run <instance_name> [options]"
    return 1
  fi
  instance_name=$1
  options=''
  if [[ ! "$2" == "" ]]; then
    options=$2
  fi
  echo "starting gcloud instance $instance_name..."
  nohup /Users/nhorn/dev/unifing/cloud/gcloud/run.sh --name $instance_name $options --keep-running > $instance_name.out &
}
function gcloud_ssh()
{
  if [[ "$1" == "" ]]; then
    echo "Usage: gcloud_ssh <instance_name>"
    return 1
  fi
  instance_name=$1
  gcloud compute ssh $instance_name --zone us-east1-b
}
function gcloud_tag()
{
  if [[ "$1" == "" ]] || [[ "$2" == "" ]] ; then
    echo "Usage: gcloud_tag <instance_name> <tag_name, e.g. oauth>"
    return 1
  fi
  instance_name=$1
  tag_name=$2
  gcloud compute instances add-tags $instance_name --tags $tag_name
}


# The next line updates PATH for the Google Cloud SDK.
source '/Users/nhorn/gcloud/google-cloud-sdk/path.bash.inc'

# The next line enables shell command completion for gcloud.
source '/Users/nhorn/gcloud/google-cloud-sdk/completion.bash.inc'

# Setting PATH for Python 2.7
# The original version is saved in .bash_profile.pysave
#PATH="/Library/Frameworks/Python.framework/Versions/2.7/bin:${PATH}"
#export PATH

